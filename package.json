{
  "name": "llm-proxy",
  "version": "1.0.0",
  "main": "src/index.js",
  "type": "module",
  "scripts": {
    "start": "node src/index.js",
    "dev": "nodemon src/index.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "llm",
    "proxy",
    "ai",
    "gpt",
    "gemini",
    "knowledge-base"
  ],
  "author": "",
  "license": "ISC",
  "description": "A flexible LLM proxy supporting multiple providers with knowledge base integration",
  "dependencies": {
    "@anthropic-ai/sdk": "^0.17.1",
    "@google-cloud/vision": "^5.3.3",
    "@google/generative-ai": "^0.2.1",
    "@supabase/supabase-js": "^2.57.4",
    "axios": "^1.6.2",
    "cheerio": "^1.0.0-rc.12",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "mammoth": "^1.6.0",
    "multer": "^1.4.5-lts.1",
    "node-cron": "^3.0.3",
    "openai": "^4.104.0",
    "pdf-parse": "^1.1.1",
    "sharp": "^0.32.6",
    "tesseract.js": "^6.0.1",
    "uuid": "^9.0.1"
  },
  "devDependencies": {
    "nodemon": "^3.0.2"
  }
}
